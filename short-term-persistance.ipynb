{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f17712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (1.0.6)\n",
      "Requirement already satisfied: langgraph-checkpoint-postgres in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: langchain-openai in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (1.1.7)\n",
      "Requirement already satisfied: psycopg[binary,pool] in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: langchain-core>=0.1 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langgraph) (1.2.7)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langgraph) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langgraph) (0.3.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langgraph) (2.12.5)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
      "Requirement already satisfied: psycopg-pool>=3.2.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langgraph-checkpoint-postgres) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from psycopg[binary,pool]) (4.15.0)\n",
      "Requirement already satisfied: tzdata in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from psycopg[binary,pool]) (2025.3)\n",
      "Requirement already satisfied: psycopg-binary==3.3.2 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from psycopg[binary,pool]) (3.3.2)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langchain-openai) (2.15.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.6.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
      "Requirement already satisfied: anyio in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (4.12.1)\n",
      "Requirement already satisfied: certifi in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.6.3)\n",
      "Requirement already satisfied: colorama in e:\\agentic ai\\langchain-langgraph\\langc\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \\\n",
    "  langgraph \\\n",
    "  langgraph-checkpoint-postgres \\\n",
    "  psycopg[binary,pool] \\\n",
    "  langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5895451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edf04269",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"xiaomi/mimo-v2-flash:free\",\n",
    "    api_key=os.environ.get('OPEN_ROUTER_API_KEY'),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a96a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node\n",
    "def call_model(state: MessagesState):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cabf4e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x20e1380dae0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_edge(START, \"call_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd07b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a2b92a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-1: Based on what you told me, your name is Nitish.\n"
     ]
    }
   ],
   "source": [
    "with PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n",
    "    # Run ONCE (creates tables)\n",
    "    checkpointer.setup()\n",
    "\n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "    # Thread 1 (remembers)\n",
    "    t1 = {\"configurable\": {\"thread_id\": \"thread-1\"}}\n",
    "    graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi, my name is Nitish\"}]}, t1)\n",
    "    out1 = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]}, t1)\n",
    "    print(\"Thread-1:\", out1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c3633eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-2: As an AI, I do not have access to your personal information, your identity, or any stored data about you. I only know what you tell me during our conversation.\n",
      "\n",
      "If you haven't told me your name in our current conversation, I cannot know it.\n"
     ]
    }
   ],
   "source": [
    "with PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n",
    "    # Run ONCE (creates tables)\n",
    "    checkpointer.setup()\n",
    "\n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "    # Thread 2 (fresh)\n",
    "    t2 = {\"configurable\": {\"thread_id\": \"thread-2\"}}\n",
    "    out2 = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]}, t2)\n",
    "    print(\"Thread-2:\", out2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7996281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last message: Based on what you told me, your name is Nitish.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres\"\n",
    "t1 = {\"configurable\": {\"thread_id\": \"thread-1\"}}\n",
    "\n",
    "with PostgresSaver.from_conn_string(DB_URI) as cp:\n",
    "    g = builder.compile(checkpointer=cp)\n",
    "\n",
    "    snap = g.get_state(t1)  # <-- pulls from Postgres\n",
    "    msgs = snap.values.get(\"messages\", [])\n",
    "    print(\"Last message:\", msgs[-1].content if msgs else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b5b228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19674b01",
   "metadata": {},
   "source": [
    "Triming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c4735a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.utils import trim_messages, count_tokens_approximately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0eaf5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 150\n",
    "def call_model(state:MessagesState):\n",
    "    messages = trim_messages(\n",
    "        state[\"messages\"],\n",
    "        strategy=\"last\",\n",
    "        token_counter=count_tokens_approximately,\n",
    "        MAX_TOKENS=MAX_TOKENS)\n",
    "    \n",
    "    print(f\"Current token count: {count_tokens_approximately(messages=messages)}\")\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9255d213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x20e17bb9c00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_edge(START, \"call_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c638c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f6a7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
