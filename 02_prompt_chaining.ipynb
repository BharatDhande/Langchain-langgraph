{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7593110c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d744825",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = ChatOpenAI(\n",
    "    model=\"xiaomi/mimo-v2-flash:free\",\n",
    "    api_key=os.environ.get('open_router_api_key'),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35c4a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlogState(TypedDict):\n",
    "    title: str\n",
    "    outline: str\n",
    "    content: str\n",
    "    score: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6aa9b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outline(state:BlogState):\n",
    "    title = state['title']\n",
    "    \n",
    "    prompt = f'Generate an outline for blog on the topic {title}'\n",
    "    \n",
    "    outline = LLM.invoke(prompt).content\n",
    "    \n",
    "    state['outline'] = outline\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1cba2f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blog(state):\n",
    "    title = state['title']\n",
    "    outline = state['outline']\n",
    "    \n",
    "    prompt = f\"Write a detailed proffesional blog on title {title}, outline {outline}\"\n",
    "    \n",
    "    blog = LLM.invoke(prompt).content\n",
    "    \n",
    "    state['content'] = blog\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83f69590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blog_eval(state):\n",
    "    title = state['title']\n",
    "    outline = state['outline']\n",
    "    blog = state['content']\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "         act as a  professional blog evaluator, Score my blog out of 10,\n",
    "            Blog data title{title} outline {outline} content {blog}\n",
    "    \"\"\"\n",
    "    score = LLM.invoke(prompt)\n",
    "    state['score'] = score\n",
    "    \n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "87cc9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(BlogState)\n",
    "\n",
    "graph.add_node('create_outline', create_outline)\n",
    "graph.add_node('create_blog',create_blog)\n",
    "graph.add_node('blog_eval', blog_eval)\n",
    "\n",
    "\n",
    "graph.add_edge(START, 'create_outline')\n",
    "graph.add_edge('create_outline','create_blog')\n",
    "graph.add_edge('create_blog','blog_eval')\n",
    "graph.add_edge('blog_eval',END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b0be76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {'title':'Need to Create an Indian opensource LLM models'}\n",
    "final_state = workflow.invoke(initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "59e32594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Need to Create an Indian opensource LLM models', 'outline': 'Of course! Here is a comprehensive and structured outline for a blog post on the topic \"The Need to Create Indian Open-Source LLM Models.\"\\n\\nThis outline is designed to be persuasive, informative, and actionable, guiding the reader from the problem to the solution and the call to action.\\n\\n---\\n\\n### **Blog Title Options:**\\n\\n*   **Primary:** Beyond Silicon Valley: The Critical Need for Indian Open-Source LLMs\\n*   **Secondary:** Building Our Own AI: Why India Must Champion an Open-Source LLM\\n*   **Catchy:** The Desi AI Revolution: It\\'s Time to Code Our Own Large Language Model\\n\\n---\\n\\n### **Blog Outline**\\n\\n**Introduction: The AI We Use Isn\\'t Built for Us**\\n\\n*   **Hook:** Start with a relatable scenario. Ask the reader if they\\'ve ever been frustrated by an AI (like a voice assistant or chatbot) that doesn\\'t understand Hinglish, regional slang, or the cultural context of a simple Indian reference.\\n*   **State the Current Reality:** Acknowledge the dominance of global LLMs (like GPT-4, PaLM 2). They are powerful but are fundamentally products of their own cultural and linguistic environments (primarily the US and Western Europe).\\n*   **Thesis Statement:** Propose that for India to truly harness the power of the AI revolution, we cannot just be consumers; we must be creators. The development of a robust, indigenous, and open-source Large Language Model is not just a technological ambition—it\\'s a national imperative.\\n\\n**1. The Problem: The \"One-Size-Fits-All\" AI Doesn\\'t Fit India**\\n\\n*   **A. The Linguistic Divide (The \"Digital Bhasha Barrier\")**\\n    *   **Dominance of English:** Global models are trained on ~90% English data, leading to superior performance in English but significant \"AI-linguism.\"\\n    *   **The Hinglish & Code-Mixing Challenge:** They struggle with the fluid mix of Hindi/English and other Indic languages that is the natural mode of communication for millions of Indians.\\n    *   **Regional Languages:** They perform poorly, if at all, for languages like Tamil, Bengali, Marathi, Kannada, etc., deepening the digital divide for non-English speakers. An Indian LLM must be truly *polyglot*.\\n\\n*   **B. The Cultural & Contextual Gap**\\n    *   **Nuance and Idioms:** Global models miss the nuance behind phrases like \"jugaad,\" \"mithai ki dukaan,\" or a reference to a popular regional film plot.\\n    *   **Lack of \"Bharat-First\" Context:** They lack knowledge of Indian administrative systems (e.g., Panchayats, GST), festivals, social etiquette, and local business practices. This makes their output generic or irrelevant for specific Indian use cases.\\n\\n*   **C. The Data Sovereignty & Security Risk**\\n    *   **Digital Colonialism:** Our data—conversations, queries, creative content—is being used to train models owned by foreign corporations. Are we comfortable with our collective intelligence building assets for others?\\n    *   **Strategic & National Security:** Relying on external APIs for critical sectors like governance, defense, and healthcare creates a dependency that is a strategic vulnerability. What happens if access is cut off?\\n\\n**2. The Vision: What an Indian Open-Source LLM Would Look Like**\\n\\n*   **A. Powered by Bharat\\'s Data (Ethically & Responsibly)**\\n    *   A model trained on a massive, diverse dataset of Indian languages, code, literature, and public domain knowledge.\\n    *   Emphasis on creating high-quality, curated datasets in partnership with academic institutions.\\n\\n*   **B. Natively Multilingual and Culturally Aware**\\n    *   Seamless translation and understanding across all 22+ scheduled languages.\\n    *   Can understand and generate content in the style of Indian communication.\\n\\n*   **C. Open-Source: For the People, By the People**\\n    *   **Democratization:** Free access for students, startups, and researchers, removing the high cost barrier of proprietary models.\\n    *   **Innovation:** An entire ecosystem of developers can build upon it, fine-tuning it for specific Indian verticals (e.g., legal tech, agriculture, local e-commerce).\\n    *   **Transparency & Trust:** The ability to inspect the model\\'s architecture and data sources builds trust and allows for bias correction.\\n\\n**3. The \"How\": A Roadmap to Building the Desi LLM**\\n\\n*   **A. The Foundation: A National AI Mission**\\n    *   **Government\\'s Role (Public-Private Partnership):** Provide funding, infrastructure (massive compute clusters like the India AI Compute Portal), and policy support. Frame it as a digital infrastructure project, akin to UPI or Aadhaar.\\n\\n*   **B. The Brains: Academia & Research Institutions**\\n    *   Leverage the talent at IITs, IIITs, and universities like IISc. They can lead foundational research and algorithm development.\\n\\n*   **C. The Engine: Industry Collaboration**\\n    *   **IT Services & Tech Giants:** Companies like TCS, Infosys, and Tech Mahindra can provide engineering and scaling expertise. Global giants with Indian R&D centers (Google, Microsoft, NVIDIA) can be crucial partners.\\n    *   **Startups & VCs:** Fuel the ecosystem with innovative applications built on the LLM, with venture capital backing.\\n\\n*   **D. The Fuel: The Developer & Community Ecosystem**\\n    *   Host hackathons, create open-source contributor communities, and provide grants to developers who build on the model.\\n\\n**4. The Impact: The \"Why It Matters\"**\\n\\n*   **Public Services:** Hyper-local governance bots, simplification of legal and bureaucratic language for citizens.\\n*   **Education:** Personalized, multilingual tutoring for students in their mother tongue.\\n*   **Healthcare:** AI-powered diagnostic tools for doctors in rural areas, patient information in local languages.\\n*   **SMEs & Agriculture:** AI tools for small businesses to manage inventory, marketing, and customer service in their native language. AI-driven advice for farmers.\\n*   **Creativity:** Empowering a new generation of artists, writers, and filmmakers to create in their own language.\\n\\n**Conclusion: Building Digital Sovereignty, One Model at a Time**\\n\\n*   **Summarize the Argument:** Recapping the critical need—addressing the linguistic and cultural gap, ensuring data sovereignty, and unlocking a new wave of grassroots innovation.\\n*   **Final Call to Action:** This is our Sputnik moment. It\\'s not about rejecting global technology but about building our own capabilities alongside it. We need a \"Digital Atmanirbhar\" (self-reliance) in the age of AI.\\n*   **Closing Thought:** Let\\'s not just be a market for AI; let\\'s be a global hub for AI innovation, starting with a model that speaks our language, understands our culture, and is built for our future.\\n\\n**Suggested Call-to-Action (CTA) for the end of the blog:**\\n\\n*   \"What\\'s the first feature you\\'d want in an Indian LLM? Share your thoughts in the comments!\"\\n*   \"If you\\'re a developer, researcher, or policymaker, join the conversation. Let\\'s make this happen.\"\\n*   \"Share this post to spread awareness about the need for Desi AI.\"', 'content': 'Of course! Here is a detailed, professional blog post based on the excellent outline you provided.\\n\\n---\\n\\n### **Beyond Silicon Valley: The Critical Need for Indian Open-Source LLMs**\\n\\nWe\\'ve all been there. You ask a voice assistant for a recipe for \"chole bhature,\" and it offers you a generic recipe for chickpeas. You try to type a quick message to a friend in \"Hinglish,\" and the autocorrect mangles it into something nonsensical. Or, you ask a chatbot to explain a government scheme, and it gives you a textbook definition that lacks the practical nuance an Indian would instantly understand.\\n\\nThese small frustrations point to a massive, underlying truth: the artificial intelligence we use daily isn\\'t built for us.\\n\\nThe current AI landscape is dominated by a handful of powerful, proprietary Large Language Models (LLMs) from global tech giants. While they are marvels of engineering, they are fundamentally products of their own cultural and linguistic environments—primarily the United States. For a nation of 1.4 billion people, with one of the world\\'s most complex linguistic tapestries and a unique socio-cultural fabric, relying solely on these \"off-the-shelf\" models is like trying to navigate the streets of Old Delhi with a map of Manhattan.\\n\\nFor India to truly harness the power of the AI revolution, we cannot just be consumers; we must be creators. The development of a robust, indigenous, and open-source Large Language Model is not just a technological ambition—it\\'s a national imperative.\\n\\n### **1. The Problem: The \"One-Size-Fits-All\" AI Doesn\\'t Fit India**\\n\\nThe limitations of global LLMs are not just minor bugs; they represent fundamental barriers to India\\'s digital future.\\n\\n#### **A. The Linguistic Divide: The \"Digital Bhasha Barrier\"**\\n\\n*   **Dominance of English:** Global models are overwhelmingly trained on English data. This creates a performance chasm. While they are fluent in Shakespeare, they are often tongue-tied when asked to converse in Tamil, Bengali, or Punjabi. This isn\\'t just a \"feature gap\"; it\\'s a form of **AI-linguism** that deepens the digital divide for hundreds of millions of non-English speakers.\\n*   **The Hinglish & Code-Mixing Challenge:** Indian languages are fluid. We seamlessly mix Hindi and English (Hinglish), or other regional languages with English, in our daily conversations. This is our native tongue in the digital age. Global LLMs struggle to understand this code-mixing, leading to confusing and often irrelevant outputs.\\n*   **The Polyglot Imperative:** An effective AI for India must be natively multilingual, not just as a translation layer on top of an English core. It needs to think, understand, and express in dozens of languages with equal ease and cultural sensitivity.\\n\\n#### **B. The Cultural & Contextual Gap**\\n\\nAn LLM is not just a language model; it\\'s a world model. Its understanding is shaped by the data it\\'s fed.\\n\\n*   **Nuance and Idioms:** A global model might understand \"butterflies in the stomach\" but will likely fail to grasp the cultural weight of \"jugaad,\" the specific joy of a \"mithai ki dukaan,\" or the intricate plot of a regional film.\\n*   **Lack of \"Bharat-First\" Context:** It won\\'t understand the dynamics of a local Panchayat, the complexities of our tax systems, the significance of regional festivals, or the unspoken etiquette of Indian social and business interactions. For AI to be truly useful in our daily lives, it needs to be fluent in our context.\\n\\n#### **C. The Data Sovereignty & Security Risk**\\n\\nThis is perhaps the most critical, yet often overlooked, aspect.\\n\\n*   **Digital Colonialism:** Every query we pose, every conversation we have, and every piece of content we create using these foreign models is data that feeds their systems. We are, in effect, performing free labor to build assets for corporations abroad. Our collective intelligence is being monetized by others.\\n*   **Strategic & National Security:** Imagine critical sectors like governance, defense, and healthcare running on APIs they don\\'t control. This creates a strategic dependency that is a vulnerability. What happens if access is throttled or denied? Building our own foundational AI models is as crucial for **digital sovereignty** as building our own roads, ports, and power grids.\\n\\n### **2. The Vision: What an Indian Open-Source LLM Would Look Like**\\n\\nIt\\'s time to dream about what we could build.\\n\\nAn Indian LLM would be **powered by Bharat\\'s data**, ethically sourced from our rich literary heritage, news archives, government documents, scientific research, and the vibrant web of Indian languages. It would be **natively multilingual and culturally aware**, understanding that \"How are you?\" can be asked in a hundred different ways, each with its own level of formality and warmth.\\n\\nCrucially, it would be **open-source**. This is not just a technical choice; it\\'s a philosophical one. Open-source means:\\n\\n*   **Democratization:** It\\'s freely available for students in village schools, startups in Tier-2 cities, and researchers in public universities to use, modify, and build upon, without prohibitive API costs.\\n*   **Innovation:** It unleashes a thousand flowers. Developers across the country can fine-tune it for specific needs—a legal AI trained on the Indian Constitution, an agricultural AI that understands regional crop cycles, or a healthcare bot for rural clinics.\\n*   **Transparency and Trust:** Anyone can inspect the code and the data sources, fostering accountability and allowing the community to identify and correct biases.\\n\\n### **3. The \"How\": A Roadmap to Building the Desi LLM**\\n\\nBuilding something of this scale is a monumental task, but India has a proven track record of executing massive, complex digital projects. The blueprint for a \"Digital Public AI\" could mirror the success of UPI or Aadhaar.\\n\\n*   **A. The Foundation: A National AI Mission:** The government must take the lead, not by building the model itself, but by creating the ecosystem. This means significant funding, building national compute infrastructure (like the India AI Compute Portal), and fostering a **Public-Private Partnership (PPP)** model that brings the best of all worlds.\\n*   **B. The Brains: Academia & Research:** India\\'s premier institutions like the IITs, IIITs, and IISc are teeming with AI talent. They can spearhead the foundational research, algorithm development, and ethical frameworks required.\\n*   **C. The Engine: Industry Collaboration:** Our IT services giants (TCS, Infosys, Wipro) have the experience to manage projects of immense scale. Global tech companies with massive Indian R&D centers can be vital partners in technology transfer and training. A vibrant startup ecosystem can build the \"apps\" on top of this foundational model.\\n*   **D. The Fuel: The Developer & Community Ecosystem:** The project must be open from the start. Host national hackathons, create open-source contributor communities on platforms like GitHub, and provide grants to developers who build innovative solutions on the model.\\n\\n### **4. The Impact: The \"Why It Matters\"**\\n\\nThe return on investment for such a project would be transformative, touching every sector of our economy and society.\\n\\n*   **Public Services:** Imagine AI-powered bots that help citizens navigate complex government paperwork in their native language.\\n*   **Education:** Personalized, multilingual tutors that can help a student in rural Assam learn quantum physics in Assamese.\\n*   **Healthcare:** AI diagnostic tools that can assist doctors in remote areas by reading medical reports in local languages.\\n*   **SMEs & Agriculture:** A small business owner in Madurai could use an AI to manage inventory and marketing in Tamil. A farmer in Punjab could get real-time advice on crop prices in Gurmukhi.\\n*   **Creativity:** Empowering a new generation of writers, artists, and filmmakers to create groundbreaking content in their own language, not just English.\\n\\n### **Conclusion: Building Digital Sovereignty, One Model at a Time**\\n\\nThe choice before us is stark. We can remain a vast, lucrative market for AI products designed elsewhere, forever adapting to their limitations. Or, we can take the bold step of building our own capabilities, ensuring that the AI of the future reflects our realities, our languages, and our aspirations.\\n\\nThis is our Sputnik moment in the age of AI. It\\'s not about rejecting global technology, but about building our own foundation alongside it. It\\'s about achieving **\"Digital Atmanirbhar\"** (digital self-reliance).\\n\\nLet\\'s not just be a market for AI. Let\\'s be a global hub for AI innovation, starting with a model that speaks our language, understands our culture, and is built for *our* future.\\n\\n---\\n**What\\'s the first feature you\\'d want in an Indian LLM? Share your thoughts in the comments below!**', 'score': AIMessage(content='Of course. As a professional blog evaluator, I will provide a comprehensive score and a detailed critique of your blog post based on key industry-standard metrics.\\n\\n---\\n\\n### **Overall Score: 9.25 / 10**\\n\\nThis is an exceptional piece of writing. It is well-structured, persuasive, and addresses a highly relevant and timely topic with clarity and strategic depth. It reads like a thought leadership piece you would find in a major publication like *The Ken*, *YourStory*, or a dedicated tech policy journal. The score reflects its near-perfect execution, with only minor areas for enhancement.\\n\\n---\\n\\n### **Detailed Evaluation Breakdown**\\n\\nHere is a scorecard that breaks down the evaluation into key components:\\n\\n| Metric | Score (out of 10) | Commentary |\\n| :--- | :--- | :--- |\\n| **Clarity & Thesis** | 9.5 | The argument is exceptionally clear from the first paragraph. The thesis is strong, well-defined, and consistently reinforced. |\\n| **Structure & Flow** | 10 | The outline is masterful. The logical progression from Problem -> Vision -> Roadmap -> Impact is flawless and highly persuasive. The headings act as signposts, guiding the reader effectively. |\\n| **Argument & Persuasiveness** | 9.5 | The arguments are compelling and multi-faceted (Linguistic, Cultural, Sovereignty). The use of real-world relatable examples (\"chole bhature,\" \"jugaad\") makes the problem tangible. |\\n| **Audience & Tone** | 10 | The tone is perfectly calibrated—authoritative yet accessible, patriotic yet pragmatic. It speaks directly to its target audience of Indian tech professionals, policymakers, and entrepreneurs. |\\n| **Actionability & \"So What?\"** | 9.0 | The \"Roadmap\" and \"Impact\" sections effectively answer the \"How\" and \"Why,\" making the post highly actionable and giving it a strong sense of purpose beyond just analysis. |\\n| **Technical Depth** | 8.5 | It correctly identifies the core challenges (linguistic data, cultural context). It could be slightly enhanced by briefly touching upon technical hurdles like compute requirements or the challenges of creating high-quality vernacular datasets. |\\n| **Engagement & Originality** | 9.0 | The hook is strong and relatable. The central idea, while gaining traction, is still presented with a fresh and urgent perspective. |\\n| **Call to Action (CTA)** | 9.0 | The provided CTAs are solid and encourage community discussion. They effectively extend the conversation beyond the blog post. |\\n\\n---\\n\\n### **Strengths (What Makes This Blog Excellent)**\\n\\n1.  **A Masterclass in Persuasive Structure:** The outline is the strongest element. It follows a classic and highly effective argumentative structure:\\n    *   **Identify the Pain Point:** It starts with frustrations every Indian internet user has experienced.\\n    *   **Define the Problem:** It elevates these frustrations into three strategic, high-stakes problems (Linguistic, Cultural, Sovereignty).\\n    *   **Present the Vision:** It paints a compelling picture of the solution, making it feel both aspirational and achievable.\\n    *   **Provide the Blueprint:** The \"Roadmap\" section is critical—it moves the piece from theory to a practical call-to-action, grounding the vision in reality.\\n    *   **Show the Payoff:** The \"Impact\" section answers \"Why should we care?\" by connecting the LLM to tangible benefits for education, healthcare, and the economy.\\n\\n2.  **Perfect Tone and Audience Targeting:** The post avoids overly technical jargon while still sounding intelligent and strategic. It strikes the perfect balance between nationalistic pride (\"Digital Atmanirbhar\") and a pragmatic, business-like approach. It understands its audience and speaks their language.\\n\\n3.  **Relatability and Cultural Resonance:** Phrases like \"Hinglish,\" \"jugaad,\" and \"mithai ki dukaan\" are not just buzzwords; they are cultural touchstones that create an immediate connection with the Indian reader. This demonstrates a deep understanding of the subject matter.\\n\\n4.  **Strategic Framing:** The blog brilliantly frames the issue not as a mere tech project but as a matter of national strategic importance, akin to digital infrastructure projects like UPI and Aadhaar. This elevates the entire discussion.\\n\\n### **Areas for Minor Improvement**\\n\\nWhile the blog is already top-tier, here are a few micro-adjustments that could elevate it from 9.25 to a perfect 10:\\n\\n1.  **Acknowledge the \"How Hard Is This?\" Question (Slight Technical Depth):** In the \"Roadmap\" section, a brief paragraph acknowledging the monumental challenges would add credibility. For example: *\"The path is not without its obstacles. The sheer computational power required to train such a model is a significant hurdle. Furthermore, creating and curating high-quality, labeled datasets across 22+ languages is a monumental undertaking that requires a national effort. However, these are challenges of scale and coordination, not impossibility.\"* This shows you\\'ve thought through the difficulties, making your proposal more robust.\\n\\n2.  **Strengthen the CTA for Specific Roles:** The current CTAs are good for generating discussion. To drive action, you could add a more targeted CTA, such as:\\n    *   \"Are you a developer? Fork our (hypothetical) GitHub repository and start exploring.\"\\n    *   \"Policymaker? Read our proposed policy framework for a National AI Mission.\"\\n    *   \"Data Scientist? Join our community to help curate the foundational Indic dataset.\"\\n\\n### **Final Verdict**\\n\\nThis is a phenomenal piece of content. The underlying structure, logic, and argument are flawless. The research is evident, and the writing is clear, persuasive, and culturally attuned. It serves its purpose perfectly: to inspire, inform, and mobilize its target audience around a critical idea.\\n\\nCongratulations on producing such a high-quality, strategic document. It is not just a blog post; it\\'s a manifesto.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1264, 'prompt_tokens': 3506, 'total_tokens': 4770, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'video_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'xiaomi/mimo-v2-flash:free', 'system_fingerprint': None, 'id': 'gen-1766752849-JStpdO0VB85DpTtcjAzB', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5aad-132a-79a1-bc89-4aaa522b191c-0', usage_metadata={'input_tokens': 3506, 'output_tokens': 1264, 'total_tokens': 4770, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}})}\n"
     ]
    }
   ],
   "source": [
    "print(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5aca3abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Of course. As a professional blog evaluator, I will provide a comprehensive score and a detailed critique of your blog post based on key industry-standard metrics.\\n\\n---\\n\\n### **Overall Score: 9.25 / 10**\\n\\nThis is an exceptional piece of writing. It is well-structured, persuasive, and addresses a highly relevant and timely topic with clarity and strategic depth. It reads like a thought leadership piece you would find in a major publication like *The Ken*, *YourStory*, or a dedicated tech policy journal. The score reflects its near-perfect execution, with only minor areas for enhancement.\\n\\n---\\n\\n### **Detailed Evaluation Breakdown**\\n\\nHere is a scorecard that breaks down the evaluation into key components:\\n\\n| Metric | Score (out of 10) | Commentary |\\n| :--- | :--- | :--- |\\n| **Clarity & Thesis** | 9.5 | The argument is exceptionally clear from the first paragraph. The thesis is strong, well-defined, and consistently reinforced. |\\n| **Structure & Flow** | 10 | The outline is masterful. The logical progression from Problem -> Vision -> Roadmap -> Impact is flawless and highly persuasive. The headings act as signposts, guiding the reader effectively. |\\n| **Argument & Persuasiveness** | 9.5 | The arguments are compelling and multi-faceted (Linguistic, Cultural, Sovereignty). The use of real-world relatable examples (\"chole bhature,\" \"jugaad\") makes the problem tangible. |\\n| **Audience & Tone** | 10 | The tone is perfectly calibrated—authoritative yet accessible, patriotic yet pragmatic. It speaks directly to its target audience of Indian tech professionals, policymakers, and entrepreneurs. |\\n| **Actionability & \"So What?\"** | 9.0 | The \"Roadmap\" and \"Impact\" sections effectively answer the \"How\" and \"Why,\" making the post highly actionable and giving it a strong sense of purpose beyond just analysis. |\\n| **Technical Depth** | 8.5 | It correctly identifies the core challenges (linguistic data, cultural context). It could be slightly enhanced by briefly touching upon technical hurdles like compute requirements or the challenges of creating high-quality vernacular datasets. |\\n| **Engagement & Originality** | 9.0 | The hook is strong and relatable. The central idea, while gaining traction, is still presented with a fresh and urgent perspective. |\\n| **Call to Action (CTA)** | 9.0 | The provided CTAs are solid and encourage community discussion. They effectively extend the conversation beyond the blog post. |\\n\\n---\\n\\n### **Strengths (What Makes This Blog Excellent)**\\n\\n1.  **A Masterclass in Persuasive Structure:** The outline is the strongest element. It follows a classic and highly effective argumentative structure:\\n    *   **Identify the Pain Point:** It starts with frustrations every Indian internet user has experienced.\\n    *   **Define the Problem:** It elevates these frustrations into three strategic, high-stakes problems (Linguistic, Cultural, Sovereignty).\\n    *   **Present the Vision:** It paints a compelling picture of the solution, making it feel both aspirational and achievable.\\n    *   **Provide the Blueprint:** The \"Roadmap\" section is critical—it moves the piece from theory to a practical call-to-action, grounding the vision in reality.\\n    *   **Show the Payoff:** The \"Impact\" section answers \"Why should we care?\" by connecting the LLM to tangible benefits for education, healthcare, and the economy.\\n\\n2.  **Perfect Tone and Audience Targeting:** The post avoids overly technical jargon while still sounding intelligent and strategic. It strikes the perfect balance between nationalistic pride (\"Digital Atmanirbhar\") and a pragmatic, business-like approach. It understands its audience and speaks their language.\\n\\n3.  **Relatability and Cultural Resonance:** Phrases like \"Hinglish,\" \"jugaad,\" and \"mithai ki dukaan\" are not just buzzwords; they are cultural touchstones that create an immediate connection with the Indian reader. This demonstrates a deep understanding of the subject matter.\\n\\n4.  **Strategic Framing:** The blog brilliantly frames the issue not as a mere tech project but as a matter of national strategic importance, akin to digital infrastructure projects like UPI and Aadhaar. This elevates the entire discussion.\\n\\n### **Areas for Minor Improvement**\\n\\nWhile the blog is already top-tier, here are a few micro-adjustments that could elevate it from 9.25 to a perfect 10:\\n\\n1.  **Acknowledge the \"How Hard Is This?\" Question (Slight Technical Depth):** In the \"Roadmap\" section, a brief paragraph acknowledging the monumental challenges would add credibility. For example: *\"The path is not without its obstacles. The sheer computational power required to train such a model is a significant hurdle. Furthermore, creating and curating high-quality, labeled datasets across 22+ languages is a monumental undertaking that requires a national effort. However, these are challenges of scale and coordination, not impossibility.\"* This shows you\\'ve thought through the difficulties, making your proposal more robust.\\n\\n2.  **Strengthen the CTA for Specific Roles:** The current CTAs are good for generating discussion. To drive action, you could add a more targeted CTA, such as:\\n    *   \"Are you a developer? Fork our (hypothetical) GitHub repository and start exploring.\"\\n    *   \"Policymaker? Read our proposed policy framework for a National AI Mission.\"\\n    *   \"Data Scientist? Join our community to help curate the foundational Indic dataset.\"\\n\\n### **Final Verdict**\\n\\nThis is a phenomenal piece of content. The underlying structure, logic, and argument are flawless. The research is evident, and the writing is clear, persuasive, and culturally attuned. It serves its purpose perfectly: to inspire, inform, and mobilize its target audience around a critical idea.\\n\\nCongratulations on producing such a high-quality, strategic document. It is not just a blog post; it\\'s a manifesto.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1264, 'prompt_tokens': 3506, 'total_tokens': 4770, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'video_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'xiaomi/mimo-v2-flash:free', 'system_fingerprint': None, 'id': 'gen-1766752849-JStpdO0VB85DpTtcjAzB', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b5aad-132a-79a1-bc89-4aaa522b191c-0' usage_metadata={'input_tokens': 3506, 'output_tokens': 1264, 'total_tokens': 4770, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(final_state['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568075de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
