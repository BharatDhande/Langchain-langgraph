{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7593110c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d744825",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = ChatOpenAI(\n",
    "    model=\"xiaomi/mimo-v2-flash:free\",\n",
    "    api_key=os.environ.get('OPEN_ROUTER_API_KEY'),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35c4a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlogState(TypedDict):\n",
    "    title: str\n",
    "    outline: str\n",
    "    content: str\n",
    "    score: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa9b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_outline(state:BlogState):\n",
    "    title = state['title']\n",
    "    \n",
    "    prompt = f'Generate an outline for blog on the topic {title}'\n",
    "    \n",
    "    outline = LLM.invoke(prompt).content\n",
    "    \n",
    "    state['outline'] = outline\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cba2f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blog(state):\n",
    "    title = state['title']\n",
    "    outline = state['outline']\n",
    "    \n",
    "    prompt = f\"Write a detailed proffesional blog on title {title}, outline {outline}\"\n",
    "    \n",
    "    blog = LLM.invoke(prompt).content\n",
    "    \n",
    "    state['content'] = blog\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83f69590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blog_eval(state):\n",
    "    title = state['title']\n",
    "    outline = state['outline']\n",
    "    blog = state['content']\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "         act as a  professional blog evaluator, Score my blog out of 10,\n",
    "            Blog data title{title} outline {outline} content {blog}\n",
    "    \"\"\"\n",
    "    score = LLM.invoke(prompt)\n",
    "    state['score'] = score\n",
    "    \n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87cc9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(BlogState)\n",
    "\n",
    "graph.add_node('create_outline', create_outline)\n",
    "graph.add_node('create_blog',create_blog)\n",
    "graph.add_node('blog_eval', blog_eval)\n",
    "\n",
    "\n",
    "graph.add_edge(START, 'create_outline')\n",
    "graph.add_edge('create_outline','create_blog')\n",
    "graph.add_edge('create_blog','blog_eval')\n",
    "graph.add_edge('blog_eval',END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0be76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {'title':'Need to Create an Indian opensource LLM models'}\n",
    "final_state = workflow.invoke(initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59e32594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Need to Create an Indian opensource LLM models', 'outline': 'Here is a comprehensive outline for a blog post on the topic: **\"Why India Needs to Create Its Own Open-Source LLMs.\"**\\n\\n---\\n\\n### **Blog Title Options**\\n*   **Option 1 (Direct):** The Strategic Imperative: Why India Must Build Its Own Open-Source LLMs\\n*   **Option 2 (Visionary):** Beyond Silicon Valley: The Case for an Indigenous AI Stack\\n*   **Option 3 (Problem/Solution):** Decolonizing AI: Why India Needs an Open-Source Large Language Model\\n\\n---\\n\\n### **Blog Outline**\\n\\n#### **I. Introduction**\\n*   **The Hook:** Start with the current global AI landscape—dominated by US tech giants (OpenAI, Google, Anthropic).\\n*   **The Context:** Acknowledge the convenience of existing models but highlight the \"black box\" nature of closed systems.\\n*   **The Thesis Statement:** Argue that for India’s digital sovereignty, cultural preservation, and economic growth, developing a robust, indigenous open-source LLM is not just an option, but a necessity.\\n\\n#### **II. The Current Landscape: Dependence on Foreign Models**\\n*   **The Status Quo:** Indian startups and enterprises currently rely heavily on API calls to Western models.\\n*   **The Risk Factors:**\\n    *   **Geopolitical Instability:** Reliance on foreign infrastructure creates vulnerability to sanctions or API bans.\\n    *   **Data Privacy:** Sensitive Indian data (financial, health, personal) processed on servers outside the country.\\n    *   **Cost Implications:** High costs of API tokens for Indian startups vs. subsidized rates in the West.\\n\\n#### **III. The Cultural & Linguistic Imperative (Bharat vs. India)**\\n*   **Beyond English:** While Western LLMs cover English well, they struggle with the \"Long Tail\" of Indian languages.\\n    *   *Example:* Nuances in Hindi, Tamil, Bengali, Telugu, etc., are often lost in translation or treated as secondary.\\n*   **Cultural Context:** Existing models often misinterpret Indian cultural references, festivals, social hierarchies, and regional dialects.\\n*   **The Opportunity:** An Indian LLM can be trained on \"Indic Dataset\"—classical literature, regional news, and dialects—creating a model that truly understands the *subtext* of Indian communication.\\n\\n#### **IV. Sovereignty and Data Security**\\n*   **Digital Public Infrastructure (DPI):** India has successfully built UPI (Unified Payments Interface) and Aadhaar. An LLM is the next logical layer of the stack.\\n*   **Strategic Autonomy:** Control over the model weights and architecture ensures India isn\\'t subject to the ethical or political biases baked into Western models.\\n*   **Secure Deployment:** The ability to host models on Indian servers (on-premise or sovereign cloud) for government and defense applications without external dependencies.\\n\\n#### **V. Economic Impact: The \"SaaS from India 2.0\"**\\n*   **Cost Efficiency:** Training and running models optimized for Indian hardware constraints and cost structures.\\n*   **Empowering Startups:** An open-source Indian LLM allows Indian startups to build applications without paying \"rent\" to foreign AI giants.\\n*   **Job Creation:** Stimulating the AI ecosystem—from data annotators (vernacular) to ML engineers and system architects.\\n\\n#### **VI. The Open-Source Advantage**\\n*   **Why Open-Source?** (vs. closed proprietary models)\\n    *   **Transparency:** Auditable code and data for bias checking.\\n    *   **Customizability:** Indian companies can fine-tune the base model for hyper-specific use cases (e.g., legal tech for Indian courts, agritech for rural farmers).\\n    *   **Innovation:** A global community of developers (including the Indian diaspora) can contribute to the model\\'s growth.\\n*   **Case Studies (Brief):** Mention successful open-source movements (Linux, Android) and recent AI examples (Llama, Mistral) to show the viability of the open-source approach.\\n\\n#### **VII. Challenges to Overcome**\\n*   **Compute Infrastructure:** The scarcity of high-end GPUs (H100s) in India compared to the West. Discussion on government initiatives (IndiaAI Mission) to procure compute power.\\n*   **Data Quality:** Moving beyond \"quantity\" to \"quality\" data. Cleaning vernacular datasets to remove noise.\\n*   **Talent Retention:** Preventing the \"brain drain\" of top AI researchers to Silicon Valley.\\n*   **Funding:** Sustained government and private sector investment without expecting immediate quarterly returns.\\n\\n#### **VIII. The Roadmap: How to Get There**\\n*   **Collaboration:** A PPP (Public-Private Partnership) model involving government bodies (MeitY), academia (IITs, IIITs), and private enterprises.\\n*   **Data Curation:** Massive push for \"Data India\"—a mission to digitize and annotate Indian languages and knowledge bases.\\n*   **Indigenous Hardware:** Long-term investment in domestic semiconductor manufacturing to support AI workloads.\\n\\n#### **IX. Conclusion**\\n*   **Recap:** Summarize the key pillars—Sovereignty, Culture, Economy, and Innovation.\\n*   **The Vision:** An Indian LLM isn\\'t about isolationism; it\\'s about contributing a unique perspective to the global AI community.\\n*   **Call to Action:** Encourage policymakers, developers, and entrepreneurs to prioritize building the \"Indic Brain\" for the digital age.\\n\\n---\\n\\n### **Suggested Keywords for SEO**\\n*   Indian AI Sovereignty\\n*   Indic LLM\\n*   Open Source AI India\\n*   Vernacular AI models\\n*   Digital Public Infrastructure India\\n*   BharatGPT\\n\\n### **Suggested Visuals**\\n1.  **Infographic:** Map of India showing coverage of languages by current LLMs vs. potential Indic LLM.\\n2.  **Chart:** Comparison of API costs (Western models vs. potential local models).\\n3.  **Concept Art:** A visual representation of \"India’s AI Stack\" (Data -> Compute -> Model -> Application).', 'content': 'Here is a detailed, professional blog post based on the provided outline.\\n\\n***\\n\\n# Beyond Silicon Valley: The Strategic Imperative for India’s Own Open-Source LLM\\n\\n**By [Your Name/Organization]**\\n\\n## Introduction\\n\\nThe global artificial intelligence landscape is currently experiencing a gold rush, largely dominated by a handful of US-based tech giants. Models like GPT-4, Claude, and Gemini have revolutionized how we interact with technology, demonstrating unprecedented capabilities in reasoning, coding, and language generation. For Indian developers and enterprises, these tools offer incredible convenience and power.\\n\\nHowever, convenience often comes at a hidden cost. As India marches toward its $5 trillion economy goal and deepens its digital footprint, relying entirely on foreign, closed-source \"black box\" models poses significant strategic risks. The convergence of digital sovereignty, cultural preservation, and economic efficiency suggests a singular conclusion: India must urgently build its own robust, indigenous, open-source Large Language Models (LLMs).\\n\\nThis is not merely a technological preference; it is a strategic necessity for the world’s most populous nation.\\n\\n## The Current Landscape: Dependence on Foreign Models\\n\\nToday, the Indian tech ecosystem—from early-stage startups to established IT giants—relies heavily on API calls to Western models. While this has accelerated adoption, it creates a fragile foundation.\\n\\n### The Risk Factors\\n\\n1.  **Geopolitical Instability:** In a world of increasing digital fragmentation, reliance on foreign infrastructure is a vulnerability. Access to APIs can be restricted, throttled, or banned due to geopolitical tensions or regulatory changes in foreign jurisdictions.\\n2.  **Data Privacy and Residency:** When an Indian user queries an AI model, that data often traverses servers located outside the country. For sectors like finance, healthcare, and defense, processing sensitive data on foreign soil creates compliance nightmares and security risks.\\n3.  **Economic Asymmetry:** Indian startups pay the same (or higher) API token rates as their Western counterparts, yet without the purchasing power parity. This \"AI tax\" drains capital that could otherwise be reinvested into product development and local hiring.\\n\\n## The Cultural & Linguistic Imperative: Beyond \"India vs. Bharat\"\\n\\nThe most glaring gap in current global models is their inability to grasp the nuance of India’s linguistic diversity. While Western LLMs are fluent in English, they are often clumsy or inaccurate when handling the \"Long Tail\" of Indian languages.\\n\\n### The Nuance Gap\\nAn Indian LLM must be more than a translation engine. It needs to understand:\\n*   **Dialects and Registers:** The difference between Mumbai’s street slang and formal Hindi, or the distinct flavors of Tamil spoken in Chennai versus Madurai.\\n*   **Cultural Context:** References to mythology, festivals, regional cuisine, and social hierarchies often confuse foreign models. For instance, understanding the specific sentiment of a verse from the *Tirukkural* or the humor in a Bengali *Adda* requires deep cultural training data.\\n*   **Code-Switching:** Indian users frequently switch between languages mid-sentence (e.g., Hinglish). An indigenous LLM, trained on Indic datasets, can inherently understand and generate this natural flow of communication.\\n\\nBy building an \"Indic LLM,\" we move from digitizing India to truly representing it in the digital realm.\\n\\n## Sovereignty and Data Security\\n\\nIndia has set a global benchmark with its Digital Public Infrastructure (DPI)—the trio of Aadhaar, UPI, and DigiLocker. An indigenous LLM is the logical next layer of this stack.\\n\\n### Strategic Autonomy\\nControlling the model weights and architecture ensures that India is not subject to the ethical or political biases baked into Western models. We have the autonomy to define what constitutes \"alignment\" for our demographic context.\\n\\nFurthermore, the ability to deploy models on-premise or on sovereign Indian clouds is critical for government applications, public sector undertakings (PSUs), and defense. It ensures that the \"brain\" of our digital governance remains under our control.\\n\\n## Economic Impact: The \"SaaS from India 2.0\"\\n\\nIndia’s SaaS industry is projected to hit $35 billion by 2027. To sustain this growth, we must move up the value chain.\\n\\n### Reducing Costs, Increasing Customization\\nBuilding open-source models optimized for Indian hardware constraints and cost structures can significantly reduce the Total Cost of Ownership (TCO) for businesses. Instead of paying recurring API fees to foreign providers, Indian companies can fine-tune open-source base models for hyper-specific use cases—be it legal tech for Indian jurisprudence, agritech for rural farmers, or credit underwriting for the unbanked.\\n\\n### Stimulating the Ecosystem\\nAn indigenous AI stack creates a virtuous cycle. It generates demand for:\\n*   **Vernacular Data Annotators:** Creating employment in Tier 2 and Tier 3 cities.\\n*   **AI Researchers:** Providing high-quality research opportunities domestically.\\n*   **Hardware Ecosystems:** Driving demand for local compute infrastructure.\\n\\n## The Open-Source Advantage\\n\\nWhy should India bet on open-source rather than building a closed, proprietary model (like a \"Indian GPT\")?\\n\\n### Transparency and Trust\\nOpen-source models offer transparency. The code and data can be audited for biases, ensuring the model aligns with democratic values. In the age of misinformation, a transparent model builds greater public trust than a black box.\\n\\n### Customizability\\nThe open-source model allows Indian startups to take a base model and fine-tune it without licensing restrictions. This mirrors the success of Linux in the server world and Android in mobile—open platforms that enabled a global explosion of innovation.\\n\\n### Collective Progress\\nBy open-sourcing the foundational models, India can leverage its massive developer community and the global Indian diaspora to contribute to the model\\'s growth. It prevents vendor lock-in and ensures that the technology serves the public good.\\n\\n## Challenges to Overcome\\n\\nBuilding an indigenous LLM is a formidable challenge, but one that is surmountable.\\n\\n1.  **Compute Infrastructure:** The scarcity of high-end GPUs (like H100s) in India compared to the West is a bottleneck. The government’s IndiaAI Mission, which aims to provide substantial compute capacity, is a step in the right direction, but private sector participation is equally vital.\\n2.  **Data Quality:** We must move beyond quantity to quality. While there is abundant text online, cleaning vernacular datasets to remove noise, toxicity, and misinformation is a massive undertaking.\\n3.  **Talent Retention:** The \"brain drain\" of top AI researchers to Silicon Valley is real. Creating a vibrant domestic AI research ecosystem with competitive grants and infrastructure is essential to retain talent.\\n4.  **Funding:** Unlike Western Big Tech, Indian firms have lower R&D budgets. Sustained government funding and patient capital from the private sector are required to bridge the gap.\\n\\n## The Roadmap: How to Get There\\n\\nThe path to an indigenous LLM requires a concerted, multi-stakeholder effort.\\n\\n*   **Public-Private Partnerships (PPP):** A collaborative framework involving MeitY (Ministry of Electronics and Information Technology), NITI Aayog, top academic institutions (IITs, IIITs), and private enterprises is non-negotiable.\\n*   **\"Data India\" Mission:** A national mission to digitize, annotate, and standardize Indian language datasets, classical texts, and legal documents to create a rich training corpus.\\n*   **Indigenous Hardware:** Long-term investment in semiconductor manufacturing (like the ISM plant in Dholera) to reduce reliance on imported chips for training and inference.\\n*   **Open-Source Frameworks:** Developing standard benchmarks and evaluation frameworks specifically for Indic languages to measure progress objectively.\\n\\n## Conclusion\\n\\nIndia stands at a crossroads. We can continue to be consumers of foreign AI, adapting our needs to fit their capabilities, or we can take ownership of our digital destiny.\\n\\nCreating an Indian open-source LLM is not an act of isolationism; it is an act of contribution. It is about ensuring that the digital future of 1.4 billion people reflects their languages, their culture, and their aspirations. By building the \"Indic Brain\" for the digital age, we secure our sovereignty, supercharge our economy, and preserve our identity in the global conversation.\\n\\nThe time to build is now.\\n\\n***\\n\\n### **Suggested Keywords**\\n*   Indian AI Sovereignty\\n*   Indic LLM\\n*   Open Source AI India\\n*   Vernacular AI models\\n*   Digital Public Infrastructure India\\n*   BharatGPT\\n\\n### **Suggested Visuals**\\n1.  **Infographic:** A map of India overlayed with color-coded nodes representing different languages, showing coverage by current Western LLMs (sparse) vs. a potential Indic LLM (dense).\\n2.  **Chart:** A comparative bar graph showing the cost of API tokens for Indian startups vs. the projected cost efficiency of running open-source models on local infrastructure.\\n3.  **Concept Art:** A visual diagram of \"India’s AI Stack\"—layering Data (Vernacular Datasets) -> Compute (Indian Data Centers) -> Model (Indic LLM) -> Applications (Health, Agri, Edu).', 'score': AIMessage(content='**Blog Evaluator Report**\\n\\n**Blog Title:** Beyond Silicon Valley: The Strategic Imperative for India’s Own Open-Source LLM\\n**Topic:** Indian AI Sovereignty / Open Source LLMs\\n**Total Score:** **8.5 / 10**\\n\\n---\\n\\n### **Detailed Analysis**\\n\\n#### **1. Content Quality & Depth (9/10)**\\n*   **Strengths:** The blog strikes an excellent balance between visionary rhetoric and concrete technical/economic realities. It successfully moves beyond generic \"AI is cool\" talking points to address specific Indian nuances (Hinglish, vernacular data, UPI context).\\n*   **Argumentation:** The flow is logical. It moves from the problem (dependence) to the cultural imperative, then to sovereignty, economics, and finally execution. The distinction between \"India\" and \"Bharat\" regarding language models is particularly sharp and necessary.\\n*   **Nuance:** The inclusion of \"Challenges\" (Section VII) elevates the piece from a wishful manifesto to a realistic strategic plan. Acknowledging the GPU scarcity and brain drain adds credibility.\\n\\n#### **2. Structure & Readability (9/10)**\\n*   **Flow:** The transitions between sections are seamless. The hook in the introduction effectively sets the stage without being overly dramatic.\\n*   **Formatting:** Excellent use of headers, subheaders, and bullet points. It is visually scannable, which is crucial for online readers.\\n*   **Pacing:** The blog is concise yet comprehensive. It covers a vast topic without becoming verbose.\\n\\n#### **3. Tone & Voice (9/10)**\\n*   **Professionalism:** The tone is authoritative, objective, and persuasive. It sounds like a policy whitepaper blended with a tech blog—perfect for the intended audience (policymakers, developers, founders).\\n*   **Language:** Vocabulary is sophisticated but accessible. Phrases like \"digital fragmentation,\" \"virtuous cycle,\" and \"vendor lock-in\" are used correctly and effectively.\\n\\n#### **4. SEO & Keywords (8/10)**\\n*   **Keyword Usage:** The suggested keywords are relevant and high-value (e.g., \"Indic LLM,\" \"Digital Public Infrastructure\").\\n*   **Integration:** The keywords are naturally woven into the body text rather than stuffed.\\n*   **Missing Element:** The blog currently lacks a \"Meta Description\" or \"Excerpt\" recommendation, which is vital for search engine click-through rates.\\n\\n#### **5. Visual Strategy (9/10)**\\n*   **Relevance:** The suggested visuals (Language map, Cost chart, Stack diagram) are perfectly aligned with the content. They provide data visualization that supports the narrative claims.\\n*   **Impact:** The \"India’s AI Stack\" concept art is a strong visual hook that simplifies a complex ecosystem.\\n\\n---\\n\\n### **Areas for Improvement (Constructive Criticism)**\\n\\n1.  **Missing a \"Call to Action\" (CTA):** While the conclusion has a general call to action, a specific CTA would increase engagement. For example, linking to the *IndiaAI Mission* website, a specific GitHub repository for Indic datasets, or a newsletter signup for AI policy updates.\\n2.  **Lack of Data Points:** The blog relies on general assertions (e.g., \"High costs of API tokens\"). Including a specific statistic or a source (e.g., \"According to a report by Nasscom...\") would make the arguments more irrefutable.\\n3.  **Visual Accessibility:** While the visual concepts are great, adding \"Alt Text\" descriptions for SEO and accessibility would be a professional touch for the final publish.\\n\\n### **Final Verdict**\\n\\nThis is a high-quality, professional-grade blog post. It addresses a timely and critical topic with a unique perspective that differentiates it from generic AI content. The outline provided the skeleton, and the final content fleshes it out with substance and strategic thinking.\\n\\n**Recommendation:** Publish as is, but consider adding a hyperlink to relevant government initiatives (like the IndiaAI mission) or open-source repositories to provide readers with immediate resources.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 845, 'prompt_tokens': 3258, 'total_tokens': 4103, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 31, 'video_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'xiaomi/mimo-v2-flash:free', 'system_fingerprint': None, 'id': 'gen-1769018063-c5xxIvwqev2ocCvDZwbj', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019be1b1-8270-7831-a6b6-4de5cde85838-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 3258, 'output_tokens': 845, 'total_tokens': 4103, 'input_token_details': {'audio': 0, 'cache_read': 31}, 'output_token_details': {'reasoning': 0}})}\n"
     ]
    }
   ],
   "source": [
    "print(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aca3abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Blog Evaluator Report**\\n\\n**Blog Title:** Beyond Silicon Valley: The Strategic Imperative for India’s Own Open-Source LLM\\n**Topic:** Indian AI Sovereignty / Open Source LLMs\\n**Total Score:** **8.5 / 10**\\n\\n---\\n\\n### **Detailed Analysis**\\n\\n#### **1. Content Quality & Depth (9/10)**\\n*   **Strengths:** The blog strikes an excellent balance between visionary rhetoric and concrete technical/economic realities. It successfully moves beyond generic \"AI is cool\" talking points to address specific Indian nuances (Hinglish, vernacular data, UPI context).\\n*   **Argumentation:** The flow is logical. It moves from the problem (dependence) to the cultural imperative, then to sovereignty, economics, and finally execution. The distinction between \"India\" and \"Bharat\" regarding language models is particularly sharp and necessary.\\n*   **Nuance:** The inclusion of \"Challenges\" (Section VII) elevates the piece from a wishful manifesto to a realistic strategic plan. Acknowledging the GPU scarcity and brain drain adds credibility.\\n\\n#### **2. Structure & Readability (9/10)**\\n*   **Flow:** The transitions between sections are seamless. The hook in the introduction effectively sets the stage without being overly dramatic.\\n*   **Formatting:** Excellent use of headers, subheaders, and bullet points. It is visually scannable, which is crucial for online readers.\\n*   **Pacing:** The blog is concise yet comprehensive. It covers a vast topic without becoming verbose.\\n\\n#### **3. Tone & Voice (9/10)**\\n*   **Professionalism:** The tone is authoritative, objective, and persuasive. It sounds like a policy whitepaper blended with a tech blog—perfect for the intended audience (policymakers, developers, founders).\\n*   **Language:** Vocabulary is sophisticated but accessible. Phrases like \"digital fragmentation,\" \"virtuous cycle,\" and \"vendor lock-in\" are used correctly and effectively.\\n\\n#### **4. SEO & Keywords (8/10)**\\n*   **Keyword Usage:** The suggested keywords are relevant and high-value (e.g., \"Indic LLM,\" \"Digital Public Infrastructure\").\\n*   **Integration:** The keywords are naturally woven into the body text rather than stuffed.\\n*   **Missing Element:** The blog currently lacks a \"Meta Description\" or \"Excerpt\" recommendation, which is vital for search engine click-through rates.\\n\\n#### **5. Visual Strategy (9/10)**\\n*   **Relevance:** The suggested visuals (Language map, Cost chart, Stack diagram) are perfectly aligned with the content. They provide data visualization that supports the narrative claims.\\n*   **Impact:** The \"India’s AI Stack\" concept art is a strong visual hook that simplifies a complex ecosystem.\\n\\n---\\n\\n### **Areas for Improvement (Constructive Criticism)**\\n\\n1.  **Missing a \"Call to Action\" (CTA):** While the conclusion has a general call to action, a specific CTA would increase engagement. For example, linking to the *IndiaAI Mission* website, a specific GitHub repository for Indic datasets, or a newsletter signup for AI policy updates.\\n2.  **Lack of Data Points:** The blog relies on general assertions (e.g., \"High costs of API tokens\"). Including a specific statistic or a source (e.g., \"According to a report by Nasscom...\") would make the arguments more irrefutable.\\n3.  **Visual Accessibility:** While the visual concepts are great, adding \"Alt Text\" descriptions for SEO and accessibility would be a professional touch for the final publish.\\n\\n### **Final Verdict**\\n\\nThis is a high-quality, professional-grade blog post. It addresses a timely and critical topic with a unique perspective that differentiates it from generic AI content. The outline provided the skeleton, and the final content fleshes it out with substance and strategic thinking.\\n\\n**Recommendation:** Publish as is, but consider adding a hyperlink to relevant government initiatives (like the IndiaAI mission) or open-source repositories to provide readers with immediate resources.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 845, 'prompt_tokens': 3258, 'total_tokens': 4103, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None, 'image_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 31, 'video_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': None, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'xiaomi/mimo-v2-flash:free', 'system_fingerprint': None, 'id': 'gen-1769018063-c5xxIvwqev2ocCvDZwbj', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019be1b1-8270-7831-a6b6-4de5cde85838-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 3258, 'output_tokens': 845, 'total_tokens': 4103, 'input_token_details': {'audio': 0, 'cache_read': 31}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(final_state['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568075de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
