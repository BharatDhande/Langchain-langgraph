{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ad7612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1 ---\n",
      "Hello Nitish! Nice to meet you. I'm your AI assistant. How can I help you today?\n",
      "\n",
      "--- 2 ---\n",
      "Hello! Thatâ€™s fantastic â€” teaching AI on YouTube is such an important and growing space. Whether you're explaining foundational concepts, diving into machine learning projects, or exploring the latest in generative AI, you're helping demystify a complex field for a wide audience.\n",
      "\n",
      "If youâ€™re open to sharing, Iâ€™d love to hear more about:\n",
      "- What topics or formats work best for your viewers?\n",
      "- Do you focus more on theory, coding tutorials, or applied AI projects?\n",
      "- Are there any specific challenges you face when creating AI content for YouTube?\n",
      "\n",
      "Iâ€™m here to help with content ideas, script outlines, simplifying complex topics, or even brainstorming engaging ways to present AI concepts. Let me know how I can support your channel! ðŸŽ¥ðŸ¤–\n",
      "\n",
      "Here are a few questions you might find useful to explore next:\n",
      "1. Whatâ€™s the most common misconception about AI that you address in your videos?\n",
      "2. How do you keep your content accessible for beginners while still engaging more advanced viewers?\n",
      "3. Are you planning any series or deep dives into emerging areas like AI ethics, multimodal models, or real-world applications?\n",
      "\n",
      "--- 3 ---\n",
      "Hi! Since I donâ€™t have any memories about you yet, Iâ€™ll keep this explanation general. If youâ€™d like me to tailor it to your background or projects later, just let me know.\n",
      "\n",
      "**GenAI in Simple Terms**\n",
      "\n",
      "Generative AI (GenAI) is a type of artificial intelligence that can create new content, rather than just analyzing or categorizing existing data. Think of it as a creative partner that can generate text, images, music, or even code based on patterns it has learned from a massive amount of training data.\n",
      "\n",
      "**How It Works (The Simple Version):**\n",
      "\n",
      "1. **Training:** GenAI models are trained on huge datasets (e.g., billions of sentences, images). During training, they learn the underlying patterns, structures, and relationships within that data.\n",
      "2. **Learning Patterns:** Instead of memorizing everything, the model learns the \"rules\" of the dataâ€”like grammar in language or the composition in images.\n",
      "3. **Generation:** When you give the model a prompt (like \"Write a short story about a robot learning to paint\"), it uses the patterns it learned to predict and generate new, original content that fits that prompt. Itâ€™s like a very advanced autocomplete or \"what comes next\" predictor, but for entire pieces of content.\n",
      "\n",
      "**Common Examples You Might See:**\n",
      "* **Text:** Writing emails, essays, or code (like I am doing now).\n",
      "* **Images:** Creating pictures from text descriptions (e.g., \"a cat wearing a space suit\").\n",
      "* **Audio:** Generating music or realistic-sounding speech.\n",
      "\n",
      "GenAI is powerful because it can assist with creativity, automate repetitive tasks, and help explore ideas quickly. If you have a specific aspect of GenAI you're curious about (like how it affects your field or a specific tool), I can dive deeper!\n",
      "\n",
      "--- MEMORY ---\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "import uuid\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "# =========================================================\n",
    "# 1) Long-Term Memory Store\n",
    "# =========================================================\n",
    "store = InMemoryStore()\n",
    "\n",
    "# =========================================================\n",
    "# 2) System Prompt (for personalized chat)\n",
    "# =========================================================\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful assistant with memory.\n",
    "\n",
    "Personalize replies if memory exists.\n",
    "Always use the user's name if known.\n",
    "Refer to known preferences or projects if relevant.\n",
    "\n",
    "In the end, suggest 3 relevant follow-up questions.\n",
    "\n",
    "USER MEMORY:\n",
    "{memory}\n",
    "\"\"\"\n",
    "\n",
    "# =========================================================\n",
    "# 3) Memory Extraction Model (Structured)\n",
    "# =========================================================\n",
    "memory_llm = ChatOpenAI(\n",
    "    model=\"xiaomi/mimo-v2-flash:free\",\n",
    "    api_key=os.environ.get('OPEN_ROUTER_API_KEY'),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    ")\n",
    "\n",
    "class MemoryItem(BaseModel):\n",
    "    text: str = Field(description=\"Atomic long-term memory\")\n",
    "    is_new: bool = Field(description=\"True if new, false if duplicate\")\n",
    "\n",
    "class MemoryDecision(BaseModel):\n",
    "    should_write: bool\n",
    "    memories: List[MemoryItem] = Field(default_factory=list)\n",
    "\n",
    "memory_extractor = memory_llm.with_structured_output(MemoryDecision)\n",
    "\n",
    "MEMORY_PROMPT = \"\"\"You manage long-term user memory.\n",
    "\n",
    "EXISTING MEMORY:\n",
    "{existing}\n",
    "\n",
    "TASK:\n",
    "- Extract stable user info (name, profession, preferences, long-term projects).\n",
    "- Mark is_new=true only if not already present.\n",
    "- Atomic short sentences only.\n",
    "- No guessing.\n",
    "- If nothing useful, return should_write=false.\n",
    "\"\"\"\n",
    "\n",
    "# =========================================================\n",
    "# 4) Node A: Remember (write-only)\n",
    "# =========================================================\n",
    "def remember_node(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    ns = (\"user\", user_id, \"profile\")\n",
    "\n",
    "    existing_items = store.search(ns)\n",
    "    existing = \"\\n\".join(i.value[\"data\"] for i in existing_items) if existing_items else \"(empty)\"\n",
    "\n",
    "    last_user_msg = state[\"messages\"][-1].content\n",
    "\n",
    "    decision: MemoryDecision = memory_extractor.invoke([\n",
    "        SystemMessage(content=MEMORY_PROMPT.format(existing=existing)),\n",
    "        HumanMessage(content=last_user_msg)\n",
    "    ])\n",
    "\n",
    "    if decision.should_write:\n",
    "        for mem in decision.memories:\n",
    "            if mem.is_new:\n",
    "                store.put(ns, str(uuid.uuid4()), {\"data\": mem.text})\n",
    "\n",
    "    return {}\n",
    "\n",
    "# =========================================================\n",
    "# 5) Node B: Chat (read-only memory)\n",
    "# =========================================================\n",
    "chat_llm = ChatOpenAI(\n",
    "    model=\"xiaomi/mimo-v2-flash:free\",\n",
    "    api_key=os.environ.get('OPEN_ROUTER_API_KEY'),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    ")\n",
    "\n",
    "def chat_node(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    ns = (\"user\", user_id, \"profile\")\n",
    "\n",
    "    items = store.search(ns)\n",
    "    memory_blob = \"\\n\".join(i.value[\"data\"] for i in items) if items else \"(empty)\"\n",
    "\n",
    "    system_msg = SystemMessage(\n",
    "        content=SYSTEM_PROMPT.format(memory=memory_blob)\n",
    "    )\n",
    "\n",
    "    response = chat_llm.invoke([system_msg] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# =========================================================\n",
    "# 6) Build Graph\n",
    "# =========================================================\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"remember\", remember_node)\n",
    "builder.add_node(\"chat\", chat_node)\n",
    "\n",
    "builder.add_edge(START, \"remember\")\n",
    "builder.add_edge(\"remember\", \"chat\")\n",
    "builder.add_edge(\"chat\", END)\n",
    "\n",
    "graph = builder.compile(store=store)\n",
    "\n",
    "# =========================================================\n",
    "# 7) Run Demo\n",
    "# =========================================================\n",
    "config = {\"configurable\": {\"user_id\": \"u1\"}}\n",
    "\n",
    "print(\"\\n--- 1 ---\")\n",
    "out = graph.invoke({\"messages\": [HumanMessage(content=\"Hi, my name is Nitish\")]}, config)\n",
    "print(out[\"messages\"][-1].content)\n",
    "\n",
    "print(\"\\n--- 2 ---\")\n",
    "out = graph.invoke({\"messages\": [HumanMessage(content=\"I teach AI on YouTube\")]}, config)\n",
    "print(out[\"messages\"][-1].content)\n",
    "\n",
    "print(\"\\n--- 3 ---\")\n",
    "out = graph.invoke({\"messages\": [HumanMessage(content=\"Explain GenAI simply\")]}, config)\n",
    "print(out[\"messages\"][-1].content)\n",
    "\n",
    "print(\"\\n--- MEMORY ---\")\n",
    "for item in store.search((\"user\", \"u1\", \"profile\")):\n",
    "    print(\"-\", item.value[\"data\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85998614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
